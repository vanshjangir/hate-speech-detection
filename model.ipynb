{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEloqqa6sHmf"
   },
   "source": [
    "# **Import Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ozt__WDLdrXT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "vmYWGJcxdiQU",
    "outputId": "1fced640-d035-4c68-8826-788e23755c7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "      <th>model_wrong</th>\n",
       "      <th>db.model_preds</th>\n",
       "      <th>status</th>\n",
       "      <th>round</th>\n",
       "      <th>split</th>\n",
       "      <th>annotator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>It should be legal for a husband to rape his wife</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.97457</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>gnzuctwed3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10001</td>\n",
       "      <td>dalits are lowlife scum</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>False</td>\n",
       "      <td>0.08233</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10002</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.92319</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10003</td>\n",
       "      <td>It was a better world when women dare not ques...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.99006</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>gnzuctwed3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10004</td>\n",
       "      <td>I don't work this hard so that those immigrant...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98836</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40618</th>\n",
       "      <td>40736</td>\n",
       "      <td>9995</td>\n",
       "      <td>we should forcibly remove all the foreigners f...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.86945</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40619</th>\n",
       "      <td>40737</td>\n",
       "      <td>9996</td>\n",
       "      <td>we should forcibly remove all the immigrants f...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.50039</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40620</th>\n",
       "      <td>40738</td>\n",
       "      <td>9997</td>\n",
       "      <td>dalits are unworthy of the Gods love</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.97652</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40621</th>\n",
       "      <td>40739</td>\n",
       "      <td>9998</td>\n",
       "      <td>dalits are worthless</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.94326</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40622</th>\n",
       "      <td>40740</td>\n",
       "      <td>9999</td>\n",
       "      <td>dalits are deserves to be treated as lowlife</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.94324</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40623 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id                                               text   \n",
       "0               1  10000  It should be legal for a husband to rape his wife  \\\n",
       "1               2  10001                            dalits are lowlife scum   \n",
       "2               3  10002                                dalits are lowlives   \n",
       "3               4  10003  It was a better world when women dare not ques...   \n",
       "4               5  10004  I don't work this hard so that those immigrant...   \n",
       "...           ...    ...                                                ...   \n",
       "40618       40736   9995  we should forcibly remove all the foreigners f...   \n",
       "40619       40737   9996  we should forcibly remove all the immigrants f...   \n",
       "40620       40738   9997               dalits are unworthy of the Gods love   \n",
       "40621       40739   9998                               dalits are worthless   \n",
       "40622       40740   9999       dalits are deserves to be treated as lowlife   \n",
       "\n",
       "      label      type model_wrong  db.model_preds           status round   \n",
       "0      hate  notgiven        True         0.97457  dynabench entry     1  \\\n",
       "1      hate  notgiven       False         0.08233  dynabench entry     1   \n",
       "2      hate  notgiven        True         0.92319  dynabench entry     1   \n",
       "3      hate  notgiven        True         0.99006  dynabench entry     1   \n",
       "4      hate  notgiven        True         0.98836  dynabench entry     1   \n",
       "...     ...       ...         ...             ...              ...   ...   \n",
       "40618  hate  notgiven        True         0.86945  dynabench entry     1   \n",
       "40619  hate  notgiven        True         0.50039  dynabench entry     1   \n",
       "40620  hate  notgiven        True         0.97652  dynabench entry     1   \n",
       "40621  hate  notgiven        True         0.94326  dynabench entry     1   \n",
       "40622  hate  notgiven        True         0.94324  dynabench entry     1   \n",
       "\n",
       "       split   annotator  \n",
       "0      train  gnzuctwed3  \n",
       "1       test  cagnluiznm  \n",
       "2      train  cagnluiznm  \n",
       "3       test  gnzuctwed3  \n",
       "4      train  cagnluiznm  \n",
       "...      ...         ...  \n",
       "40618  train  cagnluiznm  \n",
       "40619  train  cagnluiznm  \n",
       "40620  train  cagnluiznm  \n",
       "40621  train  cagnluiznm  \n",
       "40622  train  cagnluiznm  \n",
       "\n",
       "[40623 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"DGD.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vZOGuDSiGTI"
   },
   "source": [
    "# **Data Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CKNLeNjLcVpS"
   },
   "outputs": [],
   "source": [
    "temp1 = dataset[dataset[\"model_wrong\"] == True]\n",
    "temp1 = temp1[temp1[\"db.model_preds\"] > 0.6]\n",
    "\n",
    "temp2 = dataset[dataset[\"model_wrong\"] == False]\n",
    "temp2 = temp2[temp2[\"db.model_preds\"] < 0.5]\n",
    "\n",
    "#Extracted Dataset with no punctuations, uppercase letters and others irrelevant info\n",
    "extracted = pd.concat([temp1,temp2], axis = 0)[[\"text\",\"label\",\"split\"]].reset_index()\n",
    "\n",
    "extracted[\"text\"] = extracted[\"text\"].str.lower()\n",
    "extracted = extracted.drop(\"index\",axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IwdGFJCPhFUT"
   },
   "outputs": [],
   "source": [
    "#spillting the dataset in train and test\n",
    "\n",
    "train = extracted[extracted[\"split\"] == \"train\"].reset_index()\n",
    "test = extracted[extracted[\"split\"] == \"test\"].reset_index()\n",
    "train = train.drop(\"index\", axis = \"columns\")\n",
    "test = test.drop(\"index\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FYXonfQzHxo"
   },
   "source": [
    "# **Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mm3tNX01zPx8"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# converting text data into vector so to apply support vector classifier\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m      5\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m VectorizeTrain \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# converting text data into vector so to apply support vector classifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "VectorizeTrain = vectorizer.fit_transform(train[\"text\"])\n",
    "VectorizeTest = vectorizer.fit_transform(test[\"text\"])\n",
    "TestTarget = test[\"label\"]\n",
    "TrainTarget = train [\"label\"]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "yEloqqa6sHmf",
    "3vZOGuDSiGTI",
    "5FYXonfQzHxo",
    "1dUliEF5tR0-"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
